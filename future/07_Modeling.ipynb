{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook that:\n",
    "    - clean the data contained in the CSV\n",
    "    - set threshold for flow to be included in models\n",
    "    - build models (using Lasso Regression, we believe)\n",
    "    - set threshold for accuracy in predicting flow\n",
    "    - throw out models that do not meet that accuracy\n",
    "    - throw out features in models that are no longer needed\n",
    "    - do other prep for putting models into production (test in real time and have accuracy feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path=\"C:\\Springboard\\Github\\gauge_info\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USGS</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>alt</th>\n",
       "      <th>basin</th>\n",
       "      <th>lng</th>\n",
       "      <th>feat_USGS</th>\n",
       "      <th>feat_NOAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10140700</td>\n",
       "      <td>41.231819</td>\n",
       "      <td>111.984497</td>\n",
       "      <td>4285.00</td>\n",
       "      <td>Lower Weber</td>\n",
       "      <td>-111.984497</td>\n",
       "      <td>[10126000, 10092700, 10010000, 10171000, 10105...</td>\n",
       "      <td>[BCNU1, BIUI1, GSPU1, JRSU1, PRZU1, LCJU1, LGN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10149000</td>\n",
       "      <td>40.118012</td>\n",
       "      <td>111.314622</td>\n",
       "      <td>6320.00</td>\n",
       "      <td>Spanish Fork</td>\n",
       "      <td>-111.314622</td>\n",
       "      <td>[10164500, 10133800, 10133650, 10133600, 09313...</td>\n",
       "      <td>[AFPU1, ECAU1, ECPU1, MCLU1, PRHU1, PVHU1, SCJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10155200</td>\n",
       "      <td>40.554398</td>\n",
       "      <td>111.433243</td>\n",
       "      <td>5691.59</td>\n",
       "      <td>Provo</td>\n",
       "      <td>-111.433243</td>\n",
       "      <td>[10164500, 10131000, 10134500, 10132500, 10155...</td>\n",
       "      <td>[AFPU1, CIVU1, ECCU1, CRDU1, PVHU1, RBCU1, CLL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>09064600</td>\n",
       "      <td>39.553875</td>\n",
       "      <td>106.402529</td>\n",
       "      <td>8078.37</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>-106.402529</td>\n",
       "      <td>[09057500, 09034250, 09034500, 09065100, 09063...</td>\n",
       "      <td>[BGMC2, CAWC2, HTSC2, CSSC2, RERC2, FRGC2, FPT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>09081000</td>\n",
       "      <td>39.373317</td>\n",
       "      <td>107.083937</td>\n",
       "      <td>6470.00</td>\n",
       "      <td>Roaring Fork</td>\n",
       "      <td>-107.083937</td>\n",
       "      <td>[09132095, 09070500, 09085100, 09081600, 09070...</td>\n",
       "      <td>[ACSC2, EGLC2, GCOC2, RCYC2, GPSC2, ENMC2, GEP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>09073300</td>\n",
       "      <td>39.141100</td>\n",
       "      <td>106.774204</td>\n",
       "      <td>8120.00</td>\n",
       "      <td>Roaring Fork</td>\n",
       "      <td>-106.774204</td>\n",
       "      <td>[09065100, 09112500, 09078600, 09080400, 09066...</td>\n",
       "      <td>[CSSC2, ALEC2, FPTC2, RUDC2, GRVC2, GUSC2, HUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>09075400</td>\n",
       "      <td>39.193833</td>\n",
       "      <td>106.833667</td>\n",
       "      <td>7882.00</td>\n",
       "      <td>Roaring Fork</td>\n",
       "      <td>-106.833667</td>\n",
       "      <td>[09065100, 09112500, 09078600, 09080400, 09066...</td>\n",
       "      <td>[CSSC2, ALEC2, FPTC2, RUDC2, GRVC2, GUSC2, OHO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>09033300</td>\n",
       "      <td>40.006892</td>\n",
       "      <td>105.848272</td>\n",
       "      <td>8274.00</td>\n",
       "      <td>Colorado Headwaters</td>\n",
       "      <td>-105.848272</td>\n",
       "      <td>[09050700, 09010500, 09034250, 09019500, 09034...</td>\n",
       "      <td>[BLRC2, BAKC2, CAWC2, CBGC2, HTSC2, FRGC2, FRW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>09359010</td>\n",
       "      <td>37.802774</td>\n",
       "      <td>107.672839</td>\n",
       "      <td>9245.98</td>\n",
       "      <td>Animas</td>\n",
       "      <td>-107.672839</td>\n",
       "      <td>[09126000, 09118450, 09165000, 09074000, 09365...</td>\n",
       "      <td>[CMRC2, CRCC2, DRRC2, HUNC2, LPHC2, LFBC2, LFG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>09358000</td>\n",
       "      <td>37.811108</td>\n",
       "      <td>107.659228</td>\n",
       "      <td>9290.00</td>\n",
       "      <td>Animas</td>\n",
       "      <td>-107.659228</td>\n",
       "      <td>[09126000, 09118450, 09165000, 09074000, 09365...</td>\n",
       "      <td>[CMRC2, CRCC2, DRRC2, HUNC2, LPHC2, LFBC2, LFG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>09359020</td>\n",
       "      <td>37.788333</td>\n",
       "      <td>107.668222</td>\n",
       "      <td>9199.00</td>\n",
       "      <td>Animas</td>\n",
       "      <td>-107.668222</td>\n",
       "      <td>[09126000, 09118450, 09165000, 09074000, 09365...</td>\n",
       "      <td>[CMRC2, CRCC2, DRRC2, HUNC2, LPHC2, LFBC2, LFG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>09359500</td>\n",
       "      <td>37.597417</td>\n",
       "      <td>107.776967</td>\n",
       "      <td>7682.00</td>\n",
       "      <td>Animas</td>\n",
       "      <td>-107.776967</td>\n",
       "      <td>[09147000, 09166500, 09165000, 09365500, 09124...</td>\n",
       "      <td>[DCKC2, DOLC2, DRRC2, LPHC2, LFGC2, LCCC2, MNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>09146020</td>\n",
       "      <td>38.043327</td>\n",
       "      <td>107.683115</td>\n",
       "      <td>7600.00</td>\n",
       "      <td>Uncompahgre</td>\n",
       "      <td>-107.683115</td>\n",
       "      <td>[09147000, 09114500, 09365500, 09124500, 09370...</td>\n",
       "      <td>[DCKC2, GUSC2, LPHC2, LFGC2, MNRC2, OHOC2, SMP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>09112200</td>\n",
       "      <td>38.784160</td>\n",
       "      <td>106.870874</td>\n",
       "      <td>8440.00</td>\n",
       "      <td>East-Taylor</td>\n",
       "      <td>-106.870874</td>\n",
       "      <td>[09118450, 09112500, 09078600, 09114500, 09074...</td>\n",
       "      <td>[CRCC2, ALEC2, FPTC2, GUSC2, HUNC2, OHOC2, APN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>09037500</td>\n",
       "      <td>40.000200</td>\n",
       "      <td>106.180367</td>\n",
       "      <td>7808.95</td>\n",
       "      <td>Colorado Headwaters</td>\n",
       "      <td>-106.180367</td>\n",
       "      <td>[09057500, 09034250, 09019500, 09034500, 09065...</td>\n",
       "      <td>[BGMC2, CAWC2, CBGC2, HTSC2, CSSC2, FRGC2, GRV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>09413500</td>\n",
       "      <td>37.014424</td>\n",
       "      <td>113.680516</td>\n",
       "      <td>2401.58</td>\n",
       "      <td>Lower Virgin</td>\n",
       "      <td>-113.680516</td>\n",
       "      <td>[09414900, 09408195, 09418700, 09413000, 09408...</td>\n",
       "      <td>[BEAA3, FPWU1, MVRN2, SRSU1, HUCU1, HURU1, VLL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>09060799</td>\n",
       "      <td>39.891100</td>\n",
       "      <td>106.831694</td>\n",
       "      <td>6544.00</td>\n",
       "      <td>Colorado Headwaters</td>\n",
       "      <td>-106.831694</td>\n",
       "      <td>[09070500, 09081600, 09070000, 09242500, 09246...</td>\n",
       "      <td>[EGLC2, RCYC2, GPSC2, ENMC2, ELHC2, FISC2, PSB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>09421500</td>\n",
       "      <td>36.015258</td>\n",
       "      <td>114.738594</td>\n",
       "      <td>675.49</td>\n",
       "      <td>Havasu-Mohave Lakes</td>\n",
       "      <td>-114.738594</td>\n",
       "      <td>[09423000, 09419696, 09419753, 09419700, 09419...</td>\n",
       "      <td>[CBDN2, DCKN2, KIDN2, LVPN2, SAHN2, MOAN2, MUD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>385106106571000</td>\n",
       "      <td>38.851659</td>\n",
       "      <td>106.953377</td>\n",
       "      <td>8810.00</td>\n",
       "      <td>East-Taylor</td>\n",
       "      <td>-106.953377</td>\n",
       "      <td>[09126000, 09118450, 09078600, 09064000, 09074...</td>\n",
       "      <td>[CMRC2, CRCC2, FPTC2, HMSC2, HUNC2, LFBC2, ALT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>09076300</td>\n",
       "      <td>39.223200</td>\n",
       "      <td>106.857308</td>\n",
       "      <td>7575.00</td>\n",
       "      <td>Roaring Fork</td>\n",
       "      <td>-106.857308</td>\n",
       "      <td>[09067020, 09112500, 09078600, 09080400, 09114...</td>\n",
       "      <td>[EALC2, ALEC2, FPTC2, RUDC2, GUSC2, OHOC2, PSB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                USGS        lat        long      alt                basin  \\\n",
       "0           10140700  41.231819  111.984497  4285.00          Lower Weber   \n",
       "1           10149000  40.118012  111.314622  6320.00         Spanish Fork   \n",
       "2           10155200  40.554398  111.433243  5691.59                Provo   \n",
       "79          09064600  39.553875  106.402529  8078.37                Eagle   \n",
       "84          09081000  39.373317  107.083937  6470.00         Roaring Fork   \n",
       "85          09073300  39.141100  106.774204  8120.00         Roaring Fork   \n",
       "86          09075400  39.193833  106.833667  7882.00         Roaring Fork   \n",
       "87          09033300  40.006892  105.848272  8274.00  Colorado Headwaters   \n",
       "88          09359010  37.802774  107.672839  9245.98               Animas   \n",
       "92          09358000  37.811108  107.659228  9290.00               Animas   \n",
       "93          09359020  37.788333  107.668222  9199.00               Animas   \n",
       "94          09359500  37.597417  107.776967  7682.00               Animas   \n",
       "99          09146020  38.043327  107.683115  7600.00          Uncompahgre   \n",
       "100         09112200  38.784160  106.870874  8440.00          East-Taylor   \n",
       "102         09037500  40.000200  106.180367  7808.95  Colorado Headwaters   \n",
       "108         09413500  37.014424  113.680516  2401.58         Lower Virgin   \n",
       "113         09060799  39.891100  106.831694  6544.00  Colorado Headwaters   \n",
       "121         09421500  36.015258  114.738594   675.49  Havasu-Mohave Lakes   \n",
       "122  385106106571000  38.851659  106.953377  8810.00          East-Taylor   \n",
       "151         09076300  39.223200  106.857308  7575.00         Roaring Fork   \n",
       "\n",
       "            lng                                          feat_USGS  \\\n",
       "0   -111.984497  [10126000, 10092700, 10010000, 10171000, 10105...   \n",
       "1   -111.314622  [10164500, 10133800, 10133650, 10133600, 09313...   \n",
       "2   -111.433243  [10164500, 10131000, 10134500, 10132500, 10155...   \n",
       "79  -106.402529  [09057500, 09034250, 09034500, 09065100, 09063...   \n",
       "84  -107.083937  [09132095, 09070500, 09085100, 09081600, 09070...   \n",
       "85  -106.774204  [09065100, 09112500, 09078600, 09080400, 09066...   \n",
       "86  -106.833667  [09065100, 09112500, 09078600, 09080400, 09066...   \n",
       "87  -105.848272  [09050700, 09010500, 09034250, 09019500, 09034...   \n",
       "88  -107.672839  [09126000, 09118450, 09165000, 09074000, 09365...   \n",
       "92  -107.659228  [09126000, 09118450, 09165000, 09074000, 09365...   \n",
       "93  -107.668222  [09126000, 09118450, 09165000, 09074000, 09365...   \n",
       "94  -107.776967  [09147000, 09166500, 09165000, 09365500, 09124...   \n",
       "99  -107.683115  [09147000, 09114500, 09365500, 09124500, 09370...   \n",
       "100 -106.870874  [09118450, 09112500, 09078600, 09114500, 09074...   \n",
       "102 -106.180367  [09057500, 09034250, 09019500, 09034500, 09065...   \n",
       "108 -113.680516  [09414900, 09408195, 09418700, 09413000, 09408...   \n",
       "113 -106.831694  [09070500, 09081600, 09070000, 09242500, 09246...   \n",
       "121 -114.738594  [09423000, 09419696, 09419753, 09419700, 09419...   \n",
       "122 -106.953377  [09126000, 09118450, 09078600, 09064000, 09074...   \n",
       "151 -106.857308  [09067020, 09112500, 09078600, 09080400, 09114...   \n",
       "\n",
       "                                             feat_NOAA  \n",
       "0    [BCNU1, BIUI1, GSPU1, JRSU1, PRZU1, LCJU1, LGN...  \n",
       "1    [AFPU1, ECAU1, ECPU1, MCLU1, PRHU1, PVHU1, SCJ...  \n",
       "2    [AFPU1, CIVU1, ECCU1, CRDU1, PVHU1, RBCU1, CLL...  \n",
       "79   [BGMC2, CAWC2, HTSC2, CSSC2, RERC2, FRGC2, FPT...  \n",
       "84   [ACSC2, EGLC2, GCOC2, RCYC2, GPSC2, ENMC2, GEP...  \n",
       "85   [CSSC2, ALEC2, FPTC2, RUDC2, GRVC2, GUSC2, HUN...  \n",
       "86   [CSSC2, ALEC2, FPTC2, RUDC2, GRVC2, GUSC2, OHO...  \n",
       "87   [BLRC2, BAKC2, CAWC2, CBGC2, HTSC2, FRGC2, FRW...  \n",
       "88   [CMRC2, CRCC2, DRRC2, HUNC2, LPHC2, LFBC2, LFG...  \n",
       "92   [CMRC2, CRCC2, DRRC2, HUNC2, LPHC2, LFBC2, LFG...  \n",
       "93   [CMRC2, CRCC2, DRRC2, HUNC2, LPHC2, LFBC2, LFG...  \n",
       "94   [DCKC2, DOLC2, DRRC2, LPHC2, LFGC2, LCCC2, MNR...  \n",
       "99   [DCKC2, GUSC2, LPHC2, LFGC2, MNRC2, OHOC2, SMP...  \n",
       "100  [CRCC2, ALEC2, FPTC2, GUSC2, HUNC2, OHOC2, APN...  \n",
       "102  [BGMC2, CAWC2, CBGC2, HTSC2, CSSC2, FRGC2, GRV...  \n",
       "108  [BEAA3, FPWU1, MVRN2, SRSU1, HUCU1, HURU1, VLL...  \n",
       "113  [EGLC2, RCYC2, GPSC2, ENMC2, ELHC2, FISC2, PSB...  \n",
       "121  [CBDN2, DCKN2, KIDN2, LVPN2, SAHN2, MOAN2, MUD...  \n",
       "122  [CMRC2, CRCC2, FPTC2, HMSC2, HUNC2, LFBC2, ALT...  \n",
       "151  [EALC2, ALEC2, FPTC2, RUDC2, GUSC2, OHOC2, PSB...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataframe of targets and their corresponding features\n",
    "dt = pickle.load(open(\"USGS_targets.pkl\", \"rb\"))\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I want to structure this? <br>\n",
    " - loop through the rows of the data structure\n",
    " - pull in the data from the corresponding CSV files\n",
    " - parse CSV so that that flow from target (y) is first column; flow from additional features is in other columns (x's)\n",
    " - save model (what is the best data structure for saving multiple models?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, how do I parse these CSV files appropriately?!?!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw CSV back in and remove the commented lines\n",
    "raw_file = '09010500.csv'\n",
    "# open raw CSV\n",
    "fi = open(raw_file, 'r')\n",
    "\n",
    "# read raw CSV to clean CSV - eliminate comment rows with \"#\"\n",
    "clean_file = 'clean_' + raw_file\n",
    "with open(clean_file, 'w') as fo:\n",
    "    lines = fi.readlines()\n",
    "    for line in lines:\n",
    "        if \"#\" not in line:\n",
    "            fo.write(line)\n",
    "fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>18363_00060_00003</th>\n",
       "      <th>18363_00060_00003_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5s</td>\n",
       "      <td>15s</td>\n",
       "      <td>20d</td>\n",
       "      <td>14n</td>\n",
       "      <td>10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>1953-06-01</td>\n",
       "      <td>279</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>1953-06-02</td>\n",
       "      <td>286</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>1953-06-03</td>\n",
       "      <td>293</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>1953-06-04</td>\n",
       "      <td>279</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24831</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>226</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>226</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>236</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>248</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>USGS</td>\n",
       "      <td>09010500</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>242</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24836 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agency_cd   site_no    datetime 18363_00060_00003 18363_00060_00003_cd\n",
       "0            5s       15s         20d               14n                  10s\n",
       "1          USGS  09010500  1953-06-01               279                    A\n",
       "2          USGS  09010500  1953-06-02               286                    A\n",
       "3          USGS  09010500  1953-06-03               293                    A\n",
       "4          USGS  09010500  1953-06-04               279                    A\n",
       "...         ...       ...         ...               ...                  ...\n",
       "24831      USGS  09010500  2021-05-25               226                    P\n",
       "24832      USGS  09010500  2021-05-26               226                    P\n",
       "24833      USGS  09010500  2021-05-27               236                    P\n",
       "24834      USGS  09010500  2021-05-28               248                    P\n",
       "24835      USGS  09010500  2021-05-29               242                    P\n",
       "\n",
       "[24836 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see if that loads as a dataframe now\n",
    "df = pd.read_csv(clean_file, error_bad_lines=False, delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this looks great! We just need to drop the first row, the first column, the second column, and the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first row\n",
    "df.drop([0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>18363_00060_00003</th>\n",
       "      <th>18363_00060_00003_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953-06-01</td>\n",
       "      <td>279</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953-06-02</td>\n",
       "      <td>286</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-06-03</td>\n",
       "      <td>293</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953-06-04</td>\n",
       "      <td>279</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1953-06-05</td>\n",
       "      <td>264</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24831</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>226</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>226</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>236</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>248</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>242</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24835 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime 18363_00060_00003 18363_00060_00003_cd\n",
       "1      1953-06-01               279                    A\n",
       "2      1953-06-02               286                    A\n",
       "3      1953-06-03               293                    A\n",
       "4      1953-06-04               279                    A\n",
       "5      1953-06-05               264                    A\n",
       "...           ...               ...                  ...\n",
       "24831  2021-05-25               226                    P\n",
       "24832  2021-05-26               226                    P\n",
       "24833  2021-05-27               236                    P\n",
       "24834  2021-05-28               248                    P\n",
       "24835  2021-05-29               242                    P\n",
       "\n",
       "[24835 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the first and second columns\n",
    "df.drop(columns=['agency_cd', 'site_no'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18363_00060_00003_cd'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_name = list(df.columns)\n",
    "last_name[-1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>18363_00060_00003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953-06-01</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953-06-02</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-06-03</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953-06-04</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1953-06-05</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24831</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime 18363_00060_00003\n",
       "1      1953-06-01               279\n",
       "2      1953-06-02               286\n",
       "3      1953-06-03               293\n",
       "4      1953-06-04               279\n",
       "5      1953-06-05               264\n",
       "...           ...               ...\n",
       "24831  2021-05-25               226\n",
       "24832  2021-05-26               226\n",
       "24833  2021-05-27               236\n",
       "24834  2021-05-28               248\n",
       "24835  2021-05-29               242\n",
       "\n",
       "[24835 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:, :-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18363_00060_00003'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953-06-01</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953-06-02</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-06-03</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953-06-04</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1953-06-05</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24831</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         datetime flow\n",
       "1      1953-06-01  279\n",
       "2      1953-06-02  286\n",
       "3      1953-06-03  293\n",
       "4      1953-06-04  279\n",
       "5      1953-06-05  264\n",
       "...           ...  ...\n",
       "24831  2021-05-25  226\n",
       "24832  2021-05-26  226\n",
       "24833  2021-05-27  236\n",
       "24834  2021-05-28  248\n",
       "24835  2021-05-29  242\n",
       "\n",
       "[24835 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_rename = df.columns[1]\n",
    "df.rename(columns={to_rename: 'flow'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That completes pulling in the data that we would need and cleaning it - for just one gage. Let's write that into a function so the result is a df that just contains datetime and cfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(USGS):\n",
    "    # read the raw CSV back in and remove the commented lines\n",
    "    raw_file = USGS + '.csv'\n",
    "    # open raw CSV\n",
    "    try:\n",
    "        fi = open(raw_file, 'r')\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # read raw CSV to clean CSV - eliminate comment rows with \"#\"\n",
    "    clean_file = 'clean_' + raw_file\n",
    "    with open(clean_file, 'w') as fo:\n",
    "        lines = fi.readlines()\n",
    "        for line in lines:\n",
    "            if \"#\" not in line:\n",
    "                fo.write(line)\n",
    "    fi.close()\n",
    "    # reloads that clean file\n",
    "    df = pd.read_csv(clean_file, error_bad_lines=False, delimiter='\\t')\n",
    "    # drop the first row\n",
    "    df.drop([0], inplace=True)\n",
    "    # drop some other irrelevant columns\n",
    "    df.drop(columns=['agency_cd', 'site_no'], inplace=True)\n",
    "    # drop the last column\n",
    "    df = df.iloc[:, :-1]\n",
    "    # rename the remaining last column to the name of the USGS gage - better when appended\n",
    "    to_rename = df.columns[1]\n",
    "    df.rename(columns={to_rename: USGS}, inplace=True)\n",
    "    \n",
    "    # see if we can rename the column by number - use USGS as the name of the second column!!!!\n",
    "    \n",
    "    ##### consider replacing strings with other values here\n",
    "    df.replace(to_replace=['Ice', 'Ssn', 'Bkw', 'A'], value=[0, 0, 0, 0], inplace=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start to write the loop for the pulling that all into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': '10140700', 'score': 0.9289359317327344, 'intercept': 43.601634264312594, 'alpha': 0.5, '10105900': 0.04089110138002671, '10140100': 0.9600579404023674, '10141000': 0.03569280849715823}\n",
      "\n",
      "\n",
      "{'target': '09081000', 'score': 0.962031269028639, 'intercept': 56.63516796840713, 'alpha': 0.5, '09085100': 0.022671284787144426, '09085000': 0.4252467417118203}\n",
      "\n",
      "\n",
      "{'target': '09075400', 'score': 0.8479730833872321, 'intercept': 33.85078921586382, 'alpha': 0.5, '09065100': 0.6819450123818436, '09073400': 0.034971624552227805}\n",
      "\n",
      "\n",
      "{'target': '09033300', 'score': 0.8870580896203156, 'intercept': 24.56246351024012, 'alpha': 0.5, '09034250': 0.14092452335179442, '09024000': 1.6363567178843843, '09036000': 0.3997371444970451}\n",
      "\n",
      "\n",
      "{'target': '09358000', 'score': 0.8691655305528898, 'intercept': 33.98316822687872, 'alpha': 0.5, '09124500': 0.3952427293335016}\n",
      "\n",
      "\n",
      "{'target': '09359020', 'score': 0.9298574875430774, 'intercept': 45.93740051421662, 'alpha': 0.5, '09124500': 0.994546106308758}\n",
      "\n",
      "\n",
      "{'target': '09359500', 'score': 0.9529583645993988, 'intercept': 36.84848536063714, 'alpha': 0.5, '09166500': 0.09981834852879533, '09124500': 1.4925283511082585, '09342500': 0.30685463500813764}\n",
      "\n",
      "\n",
      "{'target': '09146020', 'score': 0.8748566775504453, 'intercept': 35.09220498468332, 'alpha': 0.5, '09124500': 0.41874883036882526}\n",
      "\n",
      "\n",
      "{'target': '09112200', 'score': 0.9745197119465698, 'intercept': 37.53038043883754, 'alpha': 0.5, '09112500': 0.8678116665695753}\n",
      "\n",
      "\n",
      "{'target': '09413500', 'score': 0.864515063992049, 'intercept': 35.989919918714406, 'alpha': 0.5, '09415000': 0.630977354997413}\n",
      "\n",
      "\n",
      "{'target': '09060799', 'score': 0.8219467835413105, 'intercept': 527.6903021792582, 'alpha': 1.0, '09081600': 1.5467555489712042, '09070000': 0.04814564597685218, '09237500': 4.485220222982432}\n",
      "\n",
      "\n",
      "{'target': '385106106571000', 'score': 0.8961536872095583, 'intercept': -5.60982774151509, 'alpha': 0.5, '09107000': 0.9703313457480416, '09115500': 0.5131853197037528}\n",
      "\n",
      "\n",
      "{'target': '09076300', 'score': 0.9589257380030001, 'intercept': 69.04736465999778, 'alpha': 1.0, '09067020': 0.1653406093607454, '09073400': 1.7155416311646816, '09110000': 0.01037405193862981}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# saves the list of gages that are needed\n",
    "gages_needed = []\n",
    "targets_modeled = set()\n",
    "\n",
    "\n",
    "# this loop pulls the CSV data into a dataframe\n",
    "for i, row in dt.iterrows():\n",
    "    # loads the data of the target\n",
    "    df = load_csv(row['USGS'])\n",
    "    gages = row['feat_USGS']\n",
    "    # loop to load the data of the features\n",
    "    for g in gages:\n",
    "        # load the data of each feature\n",
    "        df1 = load_csv(g)\n",
    "        # merge the dataframes - match on date\n",
    "        try:\n",
    "            df = pd.merge(df, df1, how='left', on='datetime')\n",
    "        except:\n",
    "            pass\n",
    "    # drop rows that contain NaN in the second column (target)\n",
    "    name = df.columns[1]\n",
    "    df.dropna(subset=[name], inplace=True)\n",
    "    \n",
    "    # creates backup in case we drop too many columns\n",
    "    dfb = df.copy()\n",
    "    \n",
    "    # drop any columns that contain Nan\n",
    "    df.dropna(axis=1, inplace=True)\n",
    "    \n",
    "    # check to make sure there are no NaN values and nothing is infinite\n",
    "#     print(df.isna().any())\n",
    "#     print(np.isnan(df.any()))\n",
    "#     print(np.isfinite(df.all()))\n",
    "    \n",
    "    \n",
    "    # split into X and Y\n",
    "    X, y = df.iloc[:, 2:], df.iloc[:, 1]\n",
    "    # using the LassoCV to build the model\n",
    "    if X.shape[1] > 0:\n",
    "        A = [.5, 1, 2.5, 5, 7.5, 10, 15, 20, 25, 30, 35, 40, 50, 100, 200, 250, 300, 350, 400, 450, 500, 750, 1000, 10000]\n",
    "        reg = linear_model.LassoCV(cv=5, random_state=33, alphas=A, normalize=True).fit(X, y)\n",
    "        score = reg.score(X,y)\n",
    "\n",
    "    else:\n",
    "        score = 0\n",
    "    # if there are no features left after dropping the Nan columns, we try again OR if \n",
    "    if score < 0.75:\n",
    "        df = dfb.copy()\n",
    "        # drop any rows that contain Nan (we need more features!)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "        # split into X and Y\n",
    "        X, y = df.iloc[:, 2:], df.iloc[:, 1]\n",
    "        if X.shape[1] > 0 and X.shape[0] > 0:\n",
    "            A = [.5, 1, 2.5, 5, 7.5, 10, 15, 20, 25, 30, 35, 40, 50, 100, 200, 250, 300, 350, 400, 450, 500, 750, 1000, 10000]\n",
    "            reg = linear_model.LassoCV(cv=5, random_state=33, alphas=A, normalize=True).fit(X, y)\n",
    "            score = reg.score(X,y)   \n",
    "        \n",
    "\n",
    "    # if the model is good enough, save the parameters and the model\n",
    "    \n",
    "    if score > 0.80:\n",
    "        # take the coefficients and put them in a dictionary with the title of the column as the key\n",
    "        d = {'target': name, 'score':score, 'intercept': reg.intercept_, 'alpha':reg.alpha_ }\n",
    "        # save the name so we know it can be added to the gages\n",
    "        targets_modeled.add(name)\n",
    "        features = df.columns[2:]\n",
    "        for i, feat in enumerate(features):\n",
    "            # only save the coefficients if they are greater than 0\n",
    "            if reg.coef_[i] > 0:\n",
    "                d[feat] = reg.coef_[i]\n",
    "                gages_needed.append(feat)\n",
    "    \n",
    "        print(d)\n",
    "        print('\\n')\n",
    "        # name the file after the gage\n",
    "        with open('model_' + name + '_.csv', 'w') as csv_file:  \n",
    "            writer = csv.writer(csv_file)\n",
    "            for key, value in d.items():\n",
    "                writer.writerow([key, value])\n",
    "        # save the pickled version as well\n",
    "        with open('model_deets_' + name + '_.pkl', 'wb') as handle:\n",
    "            pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        # pickle the model as well\n",
    "        with open('model_package_' + name + '_.pkl', 'wb') as handle:\n",
    "            pickle.dump(reg, handle, protocol=pickle.HIGHEST_PROTOCOL)       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is awesome! Saved all of the model information and pruned it down the models that worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10105900',\n",
       " '10140100',\n",
       " '10141000',\n",
       " '09085100',\n",
       " '09085000',\n",
       " '09065100',\n",
       " '09073400',\n",
       " '09034250',\n",
       " '09024000',\n",
       " '09036000',\n",
       " '09124500',\n",
       " '09124500',\n",
       " '09166500',\n",
       " '09124500',\n",
       " '09342500',\n",
       " '09124500',\n",
       " '09112500',\n",
       " '09415000',\n",
       " '09081600',\n",
       " '09070000',\n",
       " '09237500',\n",
       " '09107000',\n",
       " '09115500',\n",
       " '09067020',\n",
       " '09073400',\n",
       " '09110000']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gages_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gages_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['09112500',\n",
       " '09124500',\n",
       " '09115500',\n",
       " '09067020',\n",
       " '09024000',\n",
       " '09085000',\n",
       " '09073400',\n",
       " '09070000',\n",
       " '09110000',\n",
       " '09342500',\n",
       " '09034250',\n",
       " '09085100',\n",
       " '09166500',\n",
       " '10105900',\n",
       " '09237500',\n",
       " '09107000',\n",
       " '09065100',\n",
       " '09081600',\n",
       " '09415000',\n",
       " '10140100',\n",
       " '09036000',\n",
       " '10141000']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gages = list(set(gages_needed))\n",
    "model_gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_gages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save that list to CSV and pickle - DON'T NEED TO SAVE THIS AGAIN\n",
    "# with open('model_gages.csv', 'w') as myfile:\n",
    "#     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#     wr.writerow(model_gages)\n",
    "\n",
    "# # pickle the gages that we need for these models\n",
    "# with open('model_gages.pkl', 'wb') as handle:\n",
    "#     pickle.dump(model_gages, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09033300',\n",
       " '09060799',\n",
       " '09075400',\n",
       " '09076300',\n",
       " '09081000',\n",
       " '09112200',\n",
       " '09146020',\n",
       " '09358000',\n",
       " '09359020',\n",
       " '09359500',\n",
       " '09413500',\n",
       " '10140700',\n",
       " '385106106571000'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look the the targets that we were able to model:\n",
    "targets_modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Code:\n",
    "    - determine the additional NOAA predictions we need to pull\n",
    "    - add those to the list of gages to pull\n",
    "    - make sure we can pull that data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After that:\n",
    "    - determine how to integrate those models into the prediction:\n",
    "        - maybe call another python file\n",
    "        - maybe do that before the end of the other file\n",
    "    - make sure these new predictions show up on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of using the regular Cross Validation, try this:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define grid\n",
    "    grid = dict()\n",
    "    grid['alpha'] = np.arange(0.1, 1, 0.01)\n",
    "    # define search\n",
    "    search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # search for the best model\n",
    "    results = search.fit(X, y)\n",
    "    # print results of the best model\n",
    "    print('MAE: %.3f' % results.best_score_)\n",
    "    print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10126000</th>\n",
       "      <th>10092700</th>\n",
       "      <th>10171000</th>\n",
       "      <th>10105900</th>\n",
       "      <th>10168000</th>\n",
       "      <th>10109000</th>\n",
       "      <th>10140100</th>\n",
       "      <th>10136500</th>\n",
       "      <th>10141000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1680</td>\n",
       "      <td>765</td>\n",
       "      <td>187</td>\n",
       "      <td>123</td>\n",
       "      <td>12.9</td>\n",
       "      <td>217</td>\n",
       "      <td>12.5</td>\n",
       "      <td>289</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1680</td>\n",
       "      <td>814</td>\n",
       "      <td>192</td>\n",
       "      <td>179</td>\n",
       "      <td>38.0</td>\n",
       "      <td>248</td>\n",
       "      <td>26.9</td>\n",
       "      <td>403</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1730</td>\n",
       "      <td>854</td>\n",
       "      <td>179</td>\n",
       "      <td>174</td>\n",
       "      <td>18.5</td>\n",
       "      <td>239</td>\n",
       "      <td>25.3</td>\n",
       "      <td>381</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1830</td>\n",
       "      <td>766</td>\n",
       "      <td>169</td>\n",
       "      <td>159</td>\n",
       "      <td>28.2</td>\n",
       "      <td>222</td>\n",
       "      <td>21.6</td>\n",
       "      <td>297</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960</td>\n",
       "      <td>763</td>\n",
       "      <td>169</td>\n",
       "      <td>142</td>\n",
       "      <td>16.3</td>\n",
       "      <td>208</td>\n",
       "      <td>18.5</td>\n",
       "      <td>256</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>369</td>\n",
       "      <td>652</td>\n",
       "      <td>123</td>\n",
       "      <td>27.8</td>\n",
       "      <td>48.1</td>\n",
       "      <td>204</td>\n",
       "      <td>64.2</td>\n",
       "      <td>244</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>423</td>\n",
       "      <td>666</td>\n",
       "      <td>117</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.7</td>\n",
       "      <td>188</td>\n",
       "      <td>86.0</td>\n",
       "      <td>224</td>\n",
       "      <td>75.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>338</td>\n",
       "      <td>616</td>\n",
       "      <td>121</td>\n",
       "      <td>29.1</td>\n",
       "      <td>70.6</td>\n",
       "      <td>186</td>\n",
       "      <td>77.7</td>\n",
       "      <td>228</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>287</td>\n",
       "      <td>536</td>\n",
       "      <td>125</td>\n",
       "      <td>29.8</td>\n",
       "      <td>97.4</td>\n",
       "      <td>188</td>\n",
       "      <td>73.6</td>\n",
       "      <td>220</td>\n",
       "      <td>74.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>313</td>\n",
       "      <td>515</td>\n",
       "      <td>128</td>\n",
       "      <td>21.4</td>\n",
       "      <td>123</td>\n",
       "      <td>194</td>\n",
       "      <td>61.1</td>\n",
       "      <td>235</td>\n",
       "      <td>96.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3336 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     10126000 10092700 10171000 10105900 10168000 10109000 10140100 10136500  \\\n",
       "0        1680      765      187      123     12.9      217     12.5      289   \n",
       "1        1680      814      192      179     38.0      248     26.9      403   \n",
       "2        1730      854      179      174     18.5      239     25.3      381   \n",
       "3        1830      766      169      159     28.2      222     21.6      297   \n",
       "4        1960      763      169      142     16.3      208     18.5      256   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3331      369      652      123     27.8     48.1      204     64.2      244   \n",
       "3332      423      666      117     31.0     50.7      188     86.0      224   \n",
       "3333      338      616      121     29.1     70.6      186     77.7      228   \n",
       "3334      287      536      125     29.8     97.4      188     73.6      220   \n",
       "3335      313      515      128     21.4      123      194     61.1      235   \n",
       "\n",
       "     10141000  \n",
       "0         299  \n",
       "1         520  \n",
       "2         450  \n",
       "3         221  \n",
       "4         180  \n",
       "...       ...  \n",
       "3331     93.0  \n",
       "3332     75.4  \n",
       "3333     82.5  \n",
       "3334     74.6  \n",
       "3335     96.5  \n",
       "\n",
       "[3336 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # define the Lasso Model\n",
    "    model = Lasso(alpha=0.1)\n",
    "    # define the model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=33)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv)\n",
    "    # force scores to be positive\n",
    "    scores = np.absolute(scores)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       35.7\n",
       "1       48.9\n",
       "2       57.5\n",
       "3       44.5\n",
       "4       46.5\n",
       "        ... \n",
       "3331     100\n",
       "3332     117\n",
       "3333     109\n",
       "3334     107\n",
       "3335    95.7\n",
       "Name: 10140700, Length: 3336, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>09076300</th>\n",
       "      <th>09067020</th>\n",
       "      <th>09112500</th>\n",
       "      <th>09078600</th>\n",
       "      <th>09080400</th>\n",
       "      <th>09114500</th>\n",
       "      <th>09113980</th>\n",
       "      <th>09059500</th>\n",
       "      <th>09073400</th>\n",
       "      <th>09110000</th>\n",
       "      <th>09119000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>272</td>\n",
       "      <td>255</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164</td>\n",
       "      <td>395</td>\n",
       "      <td>29.7</td>\n",
       "      <td>34.8</td>\n",
       "      <td>63.3</td>\n",
       "      <td>303</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>259</td>\n",
       "      <td>243</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>375</td>\n",
       "      <td>25.1</td>\n",
       "      <td>32.5</td>\n",
       "      <td>61.3</td>\n",
       "      <td>298</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>247</td>\n",
       "      <td>227</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208</td>\n",
       "      <td>357</td>\n",
       "      <td>22.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>62.4</td>\n",
       "      <td>294</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>250</td>\n",
       "      <td>219</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207</td>\n",
       "      <td>356</td>\n",
       "      <td>22.5</td>\n",
       "      <td>29.2</td>\n",
       "      <td>72.9</td>\n",
       "      <td>298</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>244</td>\n",
       "      <td>208</td>\n",
       "      <td>118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207</td>\n",
       "      <td>343</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>72.5</td>\n",
       "      <td>296</td>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>395</td>\n",
       "      <td>885</td>\n",
       "      <td>553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>818</td>\n",
       "      <td>36.2</td>\n",
       "      <td>210</td>\n",
       "      <td>168</td>\n",
       "      <td>336</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>439</td>\n",
       "      <td>927</td>\n",
       "      <td>628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>920</td>\n",
       "      <td>35.1</td>\n",
       "      <td>221</td>\n",
       "      <td>178</td>\n",
       "      <td>371</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>406</td>\n",
       "      <td>855</td>\n",
       "      <td>544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>864</td>\n",
       "      <td>34.8</td>\n",
       "      <td>198</td>\n",
       "      <td>161</td>\n",
       "      <td>380</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>496</td>\n",
       "      <td>950</td>\n",
       "      <td>649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "      <td>959</td>\n",
       "      <td>28.5</td>\n",
       "      <td>228</td>\n",
       "      <td>187</td>\n",
       "      <td>391</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>574</td>\n",
       "      <td>962</td>\n",
       "      <td>709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>1050</td>\n",
       "      <td>23.8</td>\n",
       "      <td>220</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1064 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        datetime 09076300 09067020 09112500 09078600 09080400 09114500  \\\n",
       "0     2018-07-01      272      255      139      NaN      164      395   \n",
       "1     2018-07-02      259      243      130      NaN      198      375   \n",
       "2     2018-07-03      247      227      126      NaN      208      357   \n",
       "3     2018-07-04      250      219      125      NaN      207      356   \n",
       "4     2018-07-05      244      208      118      NaN      207      343   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "1059  2021-05-25      395      885      553      NaN      120      818   \n",
       "1060  2021-05-26      439      927      628      NaN      120      920   \n",
       "1061  2021-05-27      406      855      544      NaN      119      864   \n",
       "1062  2021-05-28      496      950      649      NaN      114      959   \n",
       "1063  2021-05-29      574      962      709      NaN      110     1050   \n",
       "\n",
       "     09113980 09059500 09073400 09110000 09119000  \n",
       "0        29.7     34.8     63.3      303     19.9  \n",
       "1        25.1     32.5     61.3      298     21.4  \n",
       "2        22.7     30.6     62.4      294     22.2  \n",
       "3        22.5     29.2     72.9      298     20.5  \n",
       "4        22.0     26.8     72.5      296     18.1  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "1059     36.2      210      168      336      120  \n",
       "1060     35.1      221      178      371      124  \n",
       "1061     34.8      198      161      380      138  \n",
       "1062     28.5      228      187      391      151  \n",
       "1063     23.8      220      202      401      173  \n",
       "\n",
       "[1064 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
